{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\krish\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\krish\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\krish\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC  \n",
    "import nltk\n",
    "from sklearn.svm import SVC\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               title  \\\n",
      "0  Obama’s Gas-Guzzling Motorcade To Paris Climat...   \n",
      "1  Obama paints Trump as no friend of the working...   \n",
      "2  BREAKING: Obama Administration To Expand Numbe...   \n",
      "3   Paul Ryan BREAKS DOWN, Admits GOP’s Trumpcare...   \n",
      "4  Justice Department seeks warrant to seize anci...   \n",
      "\n",
      "                                                text       subject  \\\n",
      "0  Are you sitting down? The phony baloney Climat...     left-news   \n",
      "1  PHILADELPHIA (Reuters) - With Hillary Clinton ...  politicsNews   \n",
      "2  So basically the Obama administration is makin...      politics   \n",
      "3  The Republican Party has had it rough. Not onl...          News   \n",
      "4  WASHINGTON (Reuters) - The U.S. Justice Depart...  politicsNews   \n",
      "\n",
      "                  date  label  \n",
      "0          Dec 2, 2015      0  \n",
      "1  September 13, 2016       1  \n",
      "2         Jan 15, 2016      0  \n",
      "3       April 27, 2017      0  \n",
      "4    December 6, 2017       1  \n"
     ]
    }
   ],
   "source": [
    "# Load Dataset\n",
    "correct_news = pd.read_csv(r\"C:\\Users\\krish\\OneDrive\\Desktop\\Boosting Financial Market Stabality With Fake News Detection\\artifacts\\True.csv\")\n",
    "fake_news = pd.read_csv(r\"C:\\Users\\krish\\OneDrive\\Desktop\\Boosting Financial Market Stabality With Fake News Detection\\artifacts\\Fake.csv\")\n",
    "\n",
    "# Add a label column: 1 for correct news, 0 for fake news\n",
    "correct_news['label'] = 1\n",
    "fake_news['label'] = 0\n",
    "\n",
    "# Combine the datasets\n",
    "data = pd.concat([correct_news, fake_news], ignore_index=True)\n",
    "\n",
    "# Shuffle the dataset\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Display the combined dataset\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    sitting phony baloney climate change summit pu...\n",
      "1    philadelphia reuters hillary clinton sidelined...\n",
      "2    basically obama administration making easier c...\n",
      "3    republican party rough admit presidential cand...\n",
      "4    washington reuters u justice department said w...\n",
      "Name: text, dtype: object\n",
      "Preprocessed true news saved to C:\\Users\\krish\\OneDrive\\Desktop\\Boosting Financial Market Stabality With Fake News Detection\\artifacts\\preprocessed_true.csv\n",
      "Preprocessed fake news saved to C:\\Users\\krish\\OneDrive\\Desktop\\Boosting Financial Market Stabality With Fake News Detection\\artifacts\\preprocessed_fake.csv\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Remove digits\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    # Tokenize\n",
    "    words = word_tokenize(text)\n",
    "    # Remove stopwords and lemmatize\n",
    "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "data['text'] = data['text'].apply(preprocess_text)\n",
    "print(data['text'].head())\n",
    "\n",
    "# Save preprocessed data into separate files\n",
    "true_news_file = r\"C:\\Users\\krish\\OneDrive\\Desktop\\Boosting Financial Market Stabality With Fake News Detection\\artifacts\\preprocessed_true.csv\"\n",
    "fake_news_file = r\"C:\\Users\\krish\\OneDrive\\Desktop\\Boosting Financial Market Stabality With Fake News Detection\\artifacts\\preprocessed_fake.csv\"\n",
    "\n",
    "# Split data into true and fake news\n",
    "true_data = data[data['label'] == 1]\n",
    "fake_data = data[data['label'] == 0]\n",
    "\n",
    "# Save to CSV\n",
    "true_data.to_csv(true_news_file, index=False)\n",
    "fake_data.to_csv(fake_news_file, index=False)\n",
    "\n",
    "print(f\"Preprocessed true news saved to {true_news_file}\")\n",
    "print(f\"Preprocessed fake news saved to {fake_news_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size: (31428, 5)\n",
      "Test data size: (9024, 5)\n",
      "Validation data size: (4446, 5)\n"
     ]
    }
   ],
   "source": [
    "# Split the data\n",
    "train_data, temp_data = train_test_split(data, test_size=0.3, random_state=42)\n",
    "test_data, val_data = train_test_split(temp_data, test_size=0.33, random_state=42)\n",
    "\n",
    "# Display the size of each split\n",
    "print(f'Train data size: {train_data.shape}')\n",
    "print(f'Test data size: {test_data.shape}')\n",
    "print(f'Validation data size: {val_data.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the text data\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train = vectorizer.fit_transform(train_data['text'])\n",
    "X_test = vectorizer.transform(test_data['text'])\n",
    "X_val = vectorizer.transform(val_data['text'])\n",
    "\n",
    "y_train = train_data['label']\n",
    "y_test = test_data['label']\n",
    "y_val = val_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - Training Data Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     16461\n",
      "           1       0.99      0.99      0.99     14967\n",
      "\n",
      "    accuracy                           0.99     31428\n",
      "   macro avg       0.99      0.99      0.99     31428\n",
      "weighted avg       0.99      0.99      0.99     31428\n",
      "\n",
      "Confusion Matrix:\n",
      "[[16291   170]\n",
      " [  122 14845]]\n",
      "Logistic Regression - Test Data Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      4732\n",
      "           1       0.98      0.99      0.98      4292\n",
      "\n",
      "    accuracy                           0.99      9024\n",
      "   macro avg       0.99      0.99      0.99      9024\n",
      "weighted avg       0.99      0.99      0.99      9024\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4644   88]\n",
      " [  43 4249]]\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the Logistic Regression model\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_train_pred = log_reg.predict(X_train)\n",
    "y_test_pred = log_reg.predict(X_test)\n",
    "\n",
    "# Classification report for training data\n",
    "print(\"Logistic Regression - Training Data Classification Report\")\n",
    "print(classification_report(y_train, y_train_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_train, y_train_pred))\n",
    "\n",
    "# Classification report for test data\n",
    "print(\"Logistic Regression - Test Data Classification Report\")\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Training Data Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     16461\n",
      "           1       1.00      1.00      1.00     14967\n",
      "\n",
      "    accuracy                           1.00     31428\n",
      "   macro avg       1.00      1.00      1.00     31428\n",
      "weighted avg       1.00      1.00      1.00     31428\n",
      "\n",
      "Confusion Matrix:\n",
      "[[16461     0]\n",
      " [    1 14966]]\n",
      "Random Forest - Test Data Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      4732\n",
      "           1       1.00      1.00      1.00      4292\n",
      "\n",
      "    accuracy                           1.00      9024\n",
      "   macro avg       1.00      1.00      1.00      9024\n",
      "weighted avg       1.00      1.00      1.00      9024\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4719   13]\n",
      " [   7 4285]]\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_train_pred_rf = rf_model.predict(X_train)\n",
    "y_test_pred_rf = rf_model.predict(X_test)\n",
    "print(\"Random Forest - Training Data Classification Report\")\n",
    "print(classification_report(y_train, y_train_pred_rf))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_train, y_train_pred_rf))\n",
    "print(\"Random Forest - Test Data Classification Report\")\n",
    "print(classification_report(y_test, y_test_pred_rf))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "svm_model = SVC(kernel='linear', random_state=42)\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_train_pred_svm = svm_model.predict(X_train)\n",
    "y_test_pred_svm = svm_model.predict(X_test)\n",
    "print(\"SVM - Training Data Classification Report\")\n",
    "print(classification_report(y_train, y_train_pred_svm))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_train, y_train_pred_svm))\n",
    "print(\"SVM - Test Data Classification Report\")\n",
    "print(classification_report(y_test, y_test_pred_svm))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_pred_svm))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
