{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mstring\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               title  \\\n",
      "0  HILLARY PAYS Professional Trolls $1 MILLION To...   \n",
      "1   The Daily Show Absolutely NAILED Absurdity Of...   \n",
      "2  Senator McCain says Russia hacking probe not i...   \n",
      "3   Wounded Veteran CONDEMNS Trump For Using Him ...   \n",
      "4   Donald Trump Storms Glenn Beckâ€™s Ted Cruz Ral...   \n",
      "\n",
      "                                                text       subject  \\\n",
      "0  It s good to be worth tens of millions of doll...     left-news   \n",
      "1  When listening to Congress discuss matters of ...          News   \n",
      "2  WASHINGTON (Reuters) - Republican U.S. Senator...  politicsNews   \n",
      "3  Donald Trump thought he could get away with us...          News   \n",
      "4  Awkward does not even come close to describing...          News   \n",
      "\n",
      "                 date  label  \n",
      "0        Apr 25, 2016      0  \n",
      "1   February 24, 2016      0  \n",
      "2    January 5, 2017       1  \n",
      "3  September 28, 2017      0  \n",
      "4   February 24, 2016      0  \n"
     ]
    }
   ],
   "source": [
    "# Load Dataset\n",
    "correct_news = pd.read_csv(r\"D:\\Important Documents\\Infosys Spring Boot Internship\\Boosting Financial Market Stabality With Fake News Detection\\Notebooks\\Data\\True.csv\")\n",
    "fake_news = pd.read_csv(r\"D:\\Important Documents\\Infosys Spring Boot Internship\\Boosting Financial Market Stabality With Fake News Detection\\Notebooks\\Data\\Fake.csv\")\n",
    "\n",
    "# Add a label column: 1 for correct news, 0 for fake news\n",
    "correct_news['label'] = 1\n",
    "fake_news['label'] = 0\n",
    "\n",
    "# Combine the datasets\n",
    "data = pd.concat([correct_news, fake_news], ignore_index=True)\n",
    "\n",
    "# Shuffle the dataset\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Display the combined dataset\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    good worth ten million dollar discover need va...\n",
      "1    listening congress discus matter importance la...\n",
      "2    washington reuters republican u senator john m...\n",
      "3    donald trump thought could get away using mili...\n",
      "4    awkward even come close describing cringeworth...\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Remove digits\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    # Tokenize\n",
    "    words = word_tokenize(text)\n",
    "    # Remove stopwords and lemmatize\n",
    "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "data['text'] = data['text'].apply(preprocess_text)\n",
    "print(data['text'].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size: (31428, 5)\n",
      "Test data size: (9024, 5)\n",
      "Validation data size: (4446, 5)\n"
     ]
    }
   ],
   "source": [
    "# Split the data\n",
    "train_data, temp_data = train_test_split(data, test_size=0.3, random_state=42)\n",
    "test_data, val_data = train_test_split(temp_data, test_size=0.33, random_state=42)\n",
    "\n",
    "# Display the size of each split\n",
    "print(f'Train data size: {train_data.shape}')\n",
    "print(f'Test data size: {test_data.shape}')\n",
    "print(f'Validation data size: {val_data.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the text data\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train = vectorizer.fit_transform(train_data['text'])\n",
    "X_test = vectorizer.transform(test_data['text'])\n",
    "X_val = vectorizer.transform(val_data['text'])\n",
    "\n",
    "y_train = train_data['label']\n",
    "y_test = test_data['label']\n",
    "y_val = val_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - Training Data Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     16479\n",
      "           1       0.99      0.99      0.99     14949\n",
      "\n",
      "    accuracy                           0.99     31428\n",
      "   macro avg       0.99      0.99      0.99     31428\n",
      "weighted avg       0.99      0.99      0.99     31428\n",
      "\n",
      "Confusion Matrix:\n",
      "[[16301   178]\n",
      " [  124 14825]]\n",
      "Logistic Regression - Test Data Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      4736\n",
      "           1       0.99      0.99      0.99      4288\n",
      "\n",
      "    accuracy                           0.99      9024\n",
      "   macro avg       0.99      0.99      0.99      9024\n",
      "weighted avg       0.99      0.99      0.99      9024\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4675   61]\n",
      " [  52 4236]]\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the Logistic Regression model\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_train_pred = log_reg.predict(X_train)\n",
    "y_test_pred = log_reg.predict(X_test)\n",
    "\n",
    "# Classification report for training data\n",
    "print(\"Logistic Regression - Training Data Classification Report\")\n",
    "print(classification_report(y_train, y_train_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_train, y_train_pred))\n",
    "\n",
    "# Classification report for test data\n",
    "print(\"Logistic Regression - Test Data Classification Report\")\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Training Data Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     16479\n",
      "           1       1.00      1.00      1.00     14949\n",
      "\n",
      "    accuracy                           1.00     31428\n",
      "   macro avg       1.00      1.00      1.00     31428\n",
      "weighted avg       1.00      1.00      1.00     31428\n",
      "\n",
      "Confusion Matrix:\n",
      "[[16479     0]\n",
      " [    0 14949]]\n",
      "Random Forest - Test Data Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      4736\n",
      "           1       1.00      1.00      1.00      4288\n",
      "\n",
      "    accuracy                           1.00      9024\n",
      "   macro avg       1.00      1.00      1.00      9024\n",
      "weighted avg       1.00      1.00      1.00      9024\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4720   16]\n",
      " [   9 4279]]\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_train_pred_rf = rf_model.predict(X_train)\n",
    "y_test_pred_rf = rf_model.predict(X_test)\n",
    "print(\"Random Forest - Training Data Classification Report\")\n",
    "print(classification_report(y_train, y_train_pred_rf))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_train, y_train_pred_rf))\n",
    "print(\"Random Forest - Test Data Classification Report\")\n",
    "print(classification_report(y_test, y_test_pred_rf))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM - Training Data Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     16479\n",
      "           1       1.00      1.00      1.00     14949\n",
      "\n",
      "    accuracy                           1.00     31428\n",
      "   macro avg       1.00      1.00      1.00     31428\n",
      "weighted avg       1.00      1.00      1.00     31428\n",
      "\n",
      "Confusion Matrix:\n",
      "[[16410    69]\n",
      " [   37 14912]]\n",
      "SVM - Test Data Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99      4736\n",
      "           1       0.99      0.99      0.99      4288\n",
      "\n",
      "    accuracy                           0.99      9024\n",
      "   macro avg       0.99      0.99      0.99      9024\n",
      "weighted avg       0.99      0.99      0.99      9024\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4693   43]\n",
      " [  23 4265]]\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "svm_model = SVC(kernel='linear', random_state=42)\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_train_pred_svm = svm_model.predict(X_train)\n",
    "y_test_pred_svm = svm_model.predict(X_test)\n",
    "print(\"SVM - Training Data Classification Report\")\n",
    "print(classification_report(y_train, y_train_pred_svm))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_train, y_train_pred_svm))\n",
    "print(\"SVM - Test Data Classification Report\")\n",
    "print(classification_report(y_test, y_test_pred_svm))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_pred_svm))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
