{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\krish\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\krish\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\krish\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC  \n",
    "import nltk\n",
    "from sklearn.svm import SVC\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               title  \\\n",
      "0  Obama’s Gas-Guzzling Motorcade To Paris Climat...   \n",
      "1  Obama paints Trump as no friend of the working...   \n",
      "2  BREAKING: Obama Administration To Expand Numbe...   \n",
      "3   Paul Ryan BREAKS DOWN, Admits GOP’s Trumpcare...   \n",
      "4  Justice Department seeks warrant to seize anci...   \n",
      "\n",
      "                                                text       subject  \\\n",
      "0  Are you sitting down? The phony baloney Climat...     left-news   \n",
      "1  PHILADELPHIA (Reuters) - With Hillary Clinton ...  politicsNews   \n",
      "2  So basically the Obama administration is makin...      politics   \n",
      "3  The Republican Party has had it rough. Not onl...          News   \n",
      "4  WASHINGTON (Reuters) - The U.S. Justice Depart...  politicsNews   \n",
      "\n",
      "                  date  label  \n",
      "0          Dec 2, 2015      0  \n",
      "1  September 13, 2016       1  \n",
      "2         Jan 15, 2016      0  \n",
      "3       April 27, 2017      0  \n",
      "4    December 6, 2017       1  \n"
     ]
    }
   ],
   "source": [
    "# Load Dataset\n",
    "correct_news = pd.read_csv(r\"C:\\Users\\krish\\OneDrive\\Desktop\\Boosting Financial Market Stabality With Fake News Detection\\artifacts\\True.csv\")\n",
    "fake_news = pd.read_csv(r\"C:\\Users\\krish\\OneDrive\\Desktop\\Boosting Financial Market Stabality With Fake News Detection\\artifacts\\Fake.csv\")\n",
    "\n",
    "# Add a label column: 1 for correct news, 0 for fake news\n",
    "correct_news['label'] = 1\n",
    "fake_news['label'] = 0\n",
    "\n",
    "# Combine the datasets\n",
    "data = pd.concat([correct_news, fake_news], ignore_index=True)\n",
    "\n",
    "# Shuffle the dataset\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Display the combined dataset\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    sitting phony baloney climate change summit pu...\n",
      "1    philadelphia reuters hillary clinton sidelined...\n",
      "2    basically obama administration making easier c...\n",
      "3    republican party rough admit presidential cand...\n",
      "4    washington reuters u justice department said w...\n",
      "Name: text, dtype: object\n",
      "Preprocessed true news saved to C:\\Users\\krish\\OneDrive\\Desktop\\Boosting Financial Market Stabality With Fake News Detection\\artifacts\\preprocessed_true.csv\n",
      "Preprocessed fake news saved to C:\\Users\\krish\\OneDrive\\Desktop\\Boosting Financial Market Stabality With Fake News Detection\\artifacts\\preprocessed_fake.csv\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Remove digits\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    # Tokenize\n",
    "    words = word_tokenize(text)\n",
    "    # Remove stopwords and lemmatize\n",
    "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "data['text'] = data['text'].apply(preprocess_text)\n",
    "print(data['text'].head())\n",
    "\n",
    "# Save preprocessed data into separate files\n",
    "true_news_file = r\"C:\\Users\\krish\\OneDrive\\Desktop\\Boosting Financial Market Stabality With Fake News Detection\\artifacts\\preprocessed_true.csv\"\n",
    "fake_news_file = r\"C:\\Users\\krish\\OneDrive\\Desktop\\Boosting Financial Market Stabality With Fake News Detection\\artifacts\\preprocessed_fake.csv\"\n",
    "\n",
    "# Split data into true and fake news\n",
    "true_data = data[data['label'] == 1]\n",
    "fake_data = data[data['label'] == 0]\n",
    "\n",
    "# Save to CSV\n",
    "true_data.to_csv(true_news_file, index=False)\n",
    "fake_data.to_csv(fake_news_file, index=False)\n",
    "\n",
    "print(f\"Preprocessed true news saved to {true_news_file}\")\n",
    "print(f\"Preprocessed fake news saved to {fake_news_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
