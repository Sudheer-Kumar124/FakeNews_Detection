{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Conv1D, MaxPooling1D, GlobalMaxPooling1D, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "true_df = pd.read_csv('True.csv')\n",
    "fake_df = pd.read_csv('Fake.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column to label the data\n",
    "true_df['label'] = 0\n",
    "fake_df['label'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the datasets\n",
    "combined_df = pd.concat([true_df, fake_df], ignore_index=True)\n",
    "\n",
    "# Shuffle the combined dataset (optional)\n",
    "combined_df = combined_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Save the combined dataset to a new CSV file\n",
    "combined_df.to_csv('Combined.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44898, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                                                    title  \\\n",
       "0      Grandmas, grandpas from travel ban states now ...   \n",
       "1      LexisNexis withdrew two products from Chinese ...   \n",
       "2      White House budget chief expects delay in hitt...   \n",
       "3      Indian Prime Minister Modi to visit Washington...   \n",
       "4      LIST OF 3 COMPANIES WHO Caved To Leftists…PULL...   \n",
       "...                                                  ...   \n",
       "44893   Confused Old Man Forgets He’s At Arlington Ce...   \n",
       "44894  LORD’S PRAYER AD BANNED…One Month Later Muslim...   \n",
       "44895   Trump Royally F*cks Veterans By Considering S...   \n",
       "44896  Britain and EU fail to agree Brexit deal on Mo...   \n",
       "44897  WATCH JUDGE TELL DISRESPECTFUL GANGBANGER Taxp...   \n",
       "\n",
       "                                                    text          subject  \\\n",
       "0      WASHINGTON (Reuters) - Grandparents of U.S. ci...     politicsNews   \n",
       "1      LONDON (Reuters) - LexisNexis, a provider of l...        worldnews   \n",
       "2      WASHINGTON (Reuters) - White House budget chie...     politicsNews   \n",
       "3      WASHINGTON (Reuters) - U.S. President Donald T...     politicsNews   \n",
       "4      Companies including Cars.com, Peloton, and Lee...        left-news   \n",
       "...                                                  ...              ...   \n",
       "44893  Donald Trump showed up at Arlington National C...             News   \n",
       "44894  This will be America if we don t push back! Lo...  Government News   \n",
       "44895  America s village idiot could soon be in charg...             News   \n",
       "44896  LONDON (Reuters) - Britain and the European Un...        worldnews   \n",
       "44897  Maybe if we had more people in positions of au...         politics   \n",
       "\n",
       "                     date  label  \n",
       "0          July 17, 2017       0  \n",
       "1        August 22, 2017       0  \n",
       "2      February 28, 2017       0  \n",
       "3         March 28, 2017       0  \n",
       "4            May 25, 2017      1  \n",
       "...                   ...    ...  \n",
       "44893        May 29, 2017      1  \n",
       "44894         May 9, 2016      1  \n",
       "44895   November 30, 2016      1  \n",
       "44896   December 4, 2017       0  \n",
       "44897        Apr 22, 2015      1  \n",
       "\n",
       "[44898 rows x 5 columns]>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of                                                    title  \\\n",
       "0      Grandmas, grandpas from travel ban states now ...   \n",
       "1      LexisNexis withdrew two products from Chinese ...   \n",
       "2      White House budget chief expects delay in hitt...   \n",
       "3      Indian Prime Minister Modi to visit Washington...   \n",
       "4      LIST OF 3 COMPANIES WHO Caved To Leftists…PULL...   \n",
       "...                                                  ...   \n",
       "44893   Confused Old Man Forgets He’s At Arlington Ce...   \n",
       "44894  LORD’S PRAYER AD BANNED…One Month Later Muslim...   \n",
       "44895   Trump Royally F*cks Veterans By Considering S...   \n",
       "44896  Britain and EU fail to agree Brexit deal on Mo...   \n",
       "44897  WATCH JUDGE TELL DISRESPECTFUL GANGBANGER Taxp...   \n",
       "\n",
       "                                                    text          subject  \\\n",
       "0      WASHINGTON (Reuters) - Grandparents of U.S. ci...     politicsNews   \n",
       "1      LONDON (Reuters) - LexisNexis, a provider of l...        worldnews   \n",
       "2      WASHINGTON (Reuters) - White House budget chie...     politicsNews   \n",
       "3      WASHINGTON (Reuters) - U.S. President Donald T...     politicsNews   \n",
       "4      Companies including Cars.com, Peloton, and Lee...        left-news   \n",
       "...                                                  ...              ...   \n",
       "44893  Donald Trump showed up at Arlington National C...             News   \n",
       "44894  This will be America if we don t push back! Lo...  Government News   \n",
       "44895  America s village idiot could soon be in charg...             News   \n",
       "44896  LONDON (Reuters) - Britain and the European Un...        worldnews   \n",
       "44897  Maybe if we had more people in positions of au...         politics   \n",
       "\n",
       "                     date  label  \n",
       "0          July 17, 2017       0  \n",
       "1        August 22, 2017       0  \n",
       "2      February 28, 2017       0  \n",
       "3         March 28, 2017       0  \n",
       "4            May 25, 2017      1  \n",
       "...                   ...    ...  \n",
       "44893        May 29, 2017      1  \n",
       "44894         May 9, 2016      1  \n",
       "44895   November 30, 2016      1  \n",
       "44896   December 4, 2017       0  \n",
       "44897        Apr 22, 2015      1  \n",
       "\n",
       "[44898 rows x 5 columns]>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.describe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preprocessing\n",
    "1) Lower Case\n",
    "2) Removing links\n",
    "3) Removing next lines (\\n)\n",
    "4) Words containing numbers\n",
    "5) Extra spaces\n",
    "6) Special characters\n",
    "7) Removal of stop words\n",
    "8) Stemming\n",
    "9) Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Grandmas, grandpas from travel ban states now ...</td>\n",
       "      <td>washington (reuters) - grandparents of u.s. ci...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>July 17, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LexisNexis withdrew two products from Chinese ...</td>\n",
       "      <td>london (reuters) - lexisnexis, a provider of l...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>August 22, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>White House budget chief expects delay in hitt...</td>\n",
       "      <td>washington (reuters) - white house budget chie...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>February 28, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Indian Prime Minister Modi to visit Washington...</td>\n",
       "      <td>washington (reuters) - u.s. president donald t...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>March 28, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LIST OF 3 COMPANIES WHO Caved To Leftists…PULL...</td>\n",
       "      <td>companies including cars.com, peloton, and lee...</td>\n",
       "      <td>left-news</td>\n",
       "      <td>May 25, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Grandmas, grandpas from travel ban states now ...   \n",
       "1  LexisNexis withdrew two products from Chinese ...   \n",
       "2  White House budget chief expects delay in hitt...   \n",
       "3  Indian Prime Minister Modi to visit Washington...   \n",
       "4  LIST OF 3 COMPANIES WHO Caved To Leftists…PULL...   \n",
       "\n",
       "                                                text       subject  \\\n",
       "0  washington (reuters) - grandparents of u.s. ci...  politicsNews   \n",
       "1  london (reuters) - lexisnexis, a provider of l...     worldnews   \n",
       "2  washington (reuters) - white house budget chie...  politicsNews   \n",
       "3  washington (reuters) - u.s. president donald t...  politicsNews   \n",
       "4  companies including cars.com, peloton, and lee...     left-news   \n",
       "\n",
       "                 date  label  \n",
       "0      July 17, 2017       0  \n",
       "1    August 22, 2017       0  \n",
       "2  February 28, 2017       0  \n",
       "3     March 28, 2017       0  \n",
       "4        May 25, 2017      1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#converting column \"text\" to lower case\n",
    "\n",
    "combined_df['text'] = combined_df['text'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>grandmas, grandpas from travel ban states now ...</td>\n",
       "      <td>washington (reuters) - grandparents of u.s. ci...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>July 17, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lexisnexis withdrew two products from chinese ...</td>\n",
       "      <td>london (reuters) - lexisnexis, a provider of l...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>August 22, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>white house budget chief expects delay in hitt...</td>\n",
       "      <td>washington (reuters) - white house budget chie...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>February 28, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>indian prime minister modi to visit washington...</td>\n",
       "      <td>washington (reuters) - u.s. president donald t...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>March 28, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>list of 3 companies who caved to leftists…pull...</td>\n",
       "      <td>companies including cars.com, peloton, and lee...</td>\n",
       "      <td>left-news</td>\n",
       "      <td>May 25, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  grandmas, grandpas from travel ban states now ...   \n",
       "1  lexisnexis withdrew two products from chinese ...   \n",
       "2  white house budget chief expects delay in hitt...   \n",
       "3  indian prime minister modi to visit washington...   \n",
       "4  list of 3 companies who caved to leftists…pull...   \n",
       "\n",
       "                                                text       subject  \\\n",
       "0  washington (reuters) - grandparents of u.s. ci...  politicsNews   \n",
       "1  london (reuters) - lexisnexis, a provider of l...     worldnews   \n",
       "2  washington (reuters) - white house budget chie...  politicsNews   \n",
       "3  washington (reuters) - u.s. president donald t...  politicsNews   \n",
       "4  companies including cars.com, peloton, and lee...     left-news   \n",
       "\n",
       "                 date  label  \n",
       "0      July 17, 2017       0  \n",
       "1    August 22, 2017       0  \n",
       "2  February 28, 2017       0  \n",
       "3     March 28, 2017       0  \n",
       "4        May 25, 2017      1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Converting \"title\" column to lower case\n",
    "\n",
    "combined_df['title'] = combined_df['title'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>grandmas, grandpas from travel ban states now ...</td>\n",
       "      <td>washington (reuters) - grandparents of u.s. ci...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>July 17, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lexisnexis withdrew two products from chinese ...</td>\n",
       "      <td>london (reuters) - lexisnexis, a provider of l...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>August 22, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>white house budget chief expects delay in hitt...</td>\n",
       "      <td>washington (reuters) - white house budget chie...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>February 28, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>indian prime minister modi to visit washington...</td>\n",
       "      <td>washington (reuters) - u.s. president donald t...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>March 28, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>list of 3 companies who caved to leftists…pull...</td>\n",
       "      <td>companies including cars.com, peloton, and lee...</td>\n",
       "      <td>left-news</td>\n",
       "      <td>May 25, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  grandmas, grandpas from travel ban states now ...   \n",
       "1  lexisnexis withdrew two products from chinese ...   \n",
       "2  white house budget chief expects delay in hitt...   \n",
       "3  indian prime minister modi to visit washington...   \n",
       "4  list of 3 companies who caved to leftists…pull...   \n",
       "\n",
       "                                                text       subject  \\\n",
       "0  washington (reuters) - grandparents of u.s. ci...  politicsNews   \n",
       "1  london (reuters) - lexisnexis, a provider of l...     worldnews   \n",
       "2  washington (reuters) - white house budget chie...  politicsNews   \n",
       "3  washington (reuters) - u.s. president donald t...  politicsNews   \n",
       "4  companies including cars.com, peloton, and lee...     left-news   \n",
       "\n",
       "                 date  label  \n",
       "0      July 17, 2017       0  \n",
       "1    August 22, 2017       0  \n",
       "2  February 28, 2017       0  \n",
       "3     March 28, 2017       0  \n",
       "4        May 25, 2017      1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove links from text and title\n",
    "\n",
    "combined_df['text'] = combined_df['text'].apply(lambda x: re.sub(r'http\\S+|www\\S+|https\\S+', '', x, flags=re.MULTILINE))\n",
    "\n",
    "combined_df['title'] = combined_df['title'].apply(lambda x: re.sub(r'http\\S+|www\\S+|https\\S+', '', x, flags=re.MULTILINE))\n",
    "\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>grandmas, grandpas from travel ban states now ...</td>\n",
       "      <td>washington (reuters) - grandparents of u.s. ci...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>July 17, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lexisnexis withdrew two products from chinese ...</td>\n",
       "      <td>london (reuters) - lexisnexis, a provider of l...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>August 22, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>white house budget chief expects delay in hitt...</td>\n",
       "      <td>washington (reuters) - white house budget chie...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>February 28, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>indian prime minister modi to visit washington...</td>\n",
       "      <td>washington (reuters) - u.s. president donald t...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>March 28, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>list of 3 companies who caved to leftists…pull...</td>\n",
       "      <td>companies including cars.com, peloton, and lee...</td>\n",
       "      <td>left-news</td>\n",
       "      <td>May 25, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  grandmas, grandpas from travel ban states now ...   \n",
       "1  lexisnexis withdrew two products from chinese ...   \n",
       "2  white house budget chief expects delay in hitt...   \n",
       "3  indian prime minister modi to visit washington...   \n",
       "4  list of 3 companies who caved to leftists…pull...   \n",
       "\n",
       "                                                text       subject  \\\n",
       "0  washington (reuters) - grandparents of u.s. ci...  politicsNews   \n",
       "1  london (reuters) - lexisnexis, a provider of l...     worldnews   \n",
       "2  washington (reuters) - white house budget chie...  politicsNews   \n",
       "3  washington (reuters) - u.s. president donald t...  politicsNews   \n",
       "4  companies including cars.com, peloton, and lee...     left-news   \n",
       "\n",
       "                 date  label  \n",
       "0      July 17, 2017       0  \n",
       "1    August 22, 2017       0  \n",
       "2  February 28, 2017       0  \n",
       "3     March 28, 2017       0  \n",
       "4        May 25, 2017      1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove newlines from text and title\n",
    "\n",
    "combined_df['text'] = combined_df['text'].str.replace('\\n', ' ')\n",
    "\n",
    "combined_df['title'] = combined_df['title'].str.replace('\\n', ' ')\n",
    "\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>grandmas, grandpas from travel ban states now ...</td>\n",
       "      <td>washington (reuters) - grandparents of u.s. ci...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>July 17, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lexisnexis withdrew two products from chinese ...</td>\n",
       "      <td>london (reuters) - lexisnexis, a provider of l...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>August 22, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>white house budget chief expects delay in hitt...</td>\n",
       "      <td>washington (reuters) - white house budget chie...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>February 28, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>indian prime minister modi to visit washington...</td>\n",
       "      <td>washington (reuters) - u.s. president donald t...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>March 28, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>list of  companies who caved to leftists…pulle...</td>\n",
       "      <td>companies including cars.com, peloton, and lee...</td>\n",
       "      <td>left-news</td>\n",
       "      <td>May 25, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  grandmas, grandpas from travel ban states now ...   \n",
       "1  lexisnexis withdrew two products from chinese ...   \n",
       "2  white house budget chief expects delay in hitt...   \n",
       "3  indian prime minister modi to visit washington...   \n",
       "4  list of  companies who caved to leftists…pulle...   \n",
       "\n",
       "                                                text       subject  \\\n",
       "0  washington (reuters) - grandparents of u.s. ci...  politicsNews   \n",
       "1  london (reuters) - lexisnexis, a provider of l...     worldnews   \n",
       "2  washington (reuters) - white house budget chie...  politicsNews   \n",
       "3  washington (reuters) - u.s. president donald t...  politicsNews   \n",
       "4  companies including cars.com, peloton, and lee...     left-news   \n",
       "\n",
       "                 date  label  \n",
       "0      July 17, 2017       0  \n",
       "1    August 22, 2017       0  \n",
       "2  February 28, 2017       0  \n",
       "3     March 28, 2017       0  \n",
       "4        May 25, 2017      1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove words containing numbers from text and title\n",
    "\n",
    "combined_df['text'] = combined_df['text'].apply(lambda x: re.sub(r'\\w*\\d\\w*', '', x))\n",
    "\n",
    "combined_df['title'] = combined_df['title'].apply(lambda x: re.sub(r'\\w*\\d\\w*', '', x))\n",
    "\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>grandmas, grandpas from travel ban states now ...</td>\n",
       "      <td>washington (reuters) - grandparents of u.s. ci...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>July 17, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lexisnexis withdrew two products from chinese ...</td>\n",
       "      <td>london (reuters) - lexisnexis, a provider of l...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>August 22, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>white house budget chief expects delay in hitt...</td>\n",
       "      <td>washington (reuters) - white house budget chie...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>February 28, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>indian prime minister modi to visit washington...</td>\n",
       "      <td>washington (reuters) - u.s. president donald t...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>March 28, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>list of companies who caved to leftists…pulled...</td>\n",
       "      <td>companies including cars.com, peloton, and lee...</td>\n",
       "      <td>left-news</td>\n",
       "      <td>May 25, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  grandmas, grandpas from travel ban states now ...   \n",
       "1  lexisnexis withdrew two products from chinese ...   \n",
       "2  white house budget chief expects delay in hitt...   \n",
       "3  indian prime minister modi to visit washington...   \n",
       "4  list of companies who caved to leftists…pulled...   \n",
       "\n",
       "                                                text       subject  \\\n",
       "0  washington (reuters) - grandparents of u.s. ci...  politicsNews   \n",
       "1  london (reuters) - lexisnexis, a provider of l...     worldnews   \n",
       "2  washington (reuters) - white house budget chie...  politicsNews   \n",
       "3  washington (reuters) - u.s. president donald t...  politicsNews   \n",
       "4  companies including cars.com, peloton, and lee...     left-news   \n",
       "\n",
       "                 date  label  \n",
       "0      July 17, 2017       0  \n",
       "1    August 22, 2017       0  \n",
       "2  February 28, 2017       0  \n",
       "3     March 28, 2017       0  \n",
       "4        May 25, 2017      1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove extra spaces from text and title\n",
    "\n",
    "combined_df['text'] = combined_df['text'].apply(lambda x: re.sub(r'\\s+', ' ', x).strip())\n",
    "\n",
    "combined_df['title'] = combined_df['title'].apply(lambda x: re.sub(r'\\s+', ' ', x).strip())\n",
    "\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>grandmas grandpas from travel ban states now w...</td>\n",
       "      <td>washington reuters  grandparents of us citizen...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>July 17, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lexisnexis withdrew two products from chinese ...</td>\n",
       "      <td>london reuters  lexisnexis a provider of legal...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>August 22, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>white house budget chief expects delay in hitt...</td>\n",
       "      <td>washington reuters  white house budget chief m...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>February 28, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>indian prime minister modi to visit washington...</td>\n",
       "      <td>washington reuters  us president donald trump ...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>March 28, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>list of companies who caved to leftistspulled ...</td>\n",
       "      <td>companies including carscom peloton and leesa ...</td>\n",
       "      <td>left-news</td>\n",
       "      <td>May 25, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  grandmas grandpas from travel ban states now w...   \n",
       "1  lexisnexis withdrew two products from chinese ...   \n",
       "2  white house budget chief expects delay in hitt...   \n",
       "3  indian prime minister modi to visit washington...   \n",
       "4  list of companies who caved to leftistspulled ...   \n",
       "\n",
       "                                                text       subject  \\\n",
       "0  washington reuters  grandparents of us citizen...  politicsNews   \n",
       "1  london reuters  lexisnexis a provider of legal...     worldnews   \n",
       "2  washington reuters  white house budget chief m...  politicsNews   \n",
       "3  washington reuters  us president donald trump ...  politicsNews   \n",
       "4  companies including carscom peloton and leesa ...     left-news   \n",
       "\n",
       "                 date  label  \n",
       "0      July 17, 2017       0  \n",
       "1    August 22, 2017       0  \n",
       "2  February 28, 2017       0  \n",
       "3     March 28, 2017       0  \n",
       "4        May 25, 2017      1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove special characters from text and title\n",
    "\n",
    "combined_df['text'] = combined_df['text'].apply(lambda x: re.sub(r'[^a-zA-Z\\s]', '', x))\n",
    "\n",
    "combined_df['title'] = combined_df['title'].apply(lambda x: re.sub(r'[^a-zA-Z\\s]', '', x))\n",
    "\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stop words from text\n",
    "filtered_texts = []\n",
    "for text in combined_df['text']:\n",
    "    filtered_text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "    filtered_texts.append(filtered_text)\n",
    "combined_df['text'] = filtered_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>grandmas grandpas travel ban states welcome us...</td>\n",
       "      <td>washington reuters grandparents us citizens si...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>July 17, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lexisnexis withdrew two products chinese market</td>\n",
       "      <td>london reuters lexisnexis provider legal regul...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>August 22, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>white house budget chief expects delay hitting...</td>\n",
       "      <td>washington reuters white house budget chief mi...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>February 28, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>indian prime minister modi visit washington ye...</td>\n",
       "      <td>washington reuters us president donald trump s...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>March 28, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>list companies caved leftistspulled ads hannit...</td>\n",
       "      <td>companies including carscom peloton leesa slee...</td>\n",
       "      <td>left-news</td>\n",
       "      <td>May 25, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  grandmas grandpas travel ban states welcome us...   \n",
       "1    lexisnexis withdrew two products chinese market   \n",
       "2  white house budget chief expects delay hitting...   \n",
       "3  indian prime minister modi visit washington ye...   \n",
       "4  list companies caved leftistspulled ads hannit...   \n",
       "\n",
       "                                                text       subject  \\\n",
       "0  washington reuters grandparents us citizens si...  politicsNews   \n",
       "1  london reuters lexisnexis provider legal regul...     worldnews   \n",
       "2  washington reuters white house budget chief mi...  politicsNews   \n",
       "3  washington reuters us president donald trump s...  politicsNews   \n",
       "4  companies including carscom peloton leesa slee...     left-news   \n",
       "\n",
       "                 date  label  \n",
       "0      July 17, 2017       0  \n",
       "1    August 22, 2017       0  \n",
       "2  February 28, 2017       0  \n",
       "3     March 28, 2017       0  \n",
       "4        May 25, 2017      1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_titles = []\n",
    "for title in combined_df['title']:\n",
    "    filtered_title = ' '.join([word for word in title.split() if word not in stop_words])\n",
    "    filtered_titles.append(filtered_title)\n",
    "combined_df['title'] = filtered_titles\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('wordnet')\n",
    "# nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatize text\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "lemmatized_texts = []\n",
    "for text in combined_df['text']:\n",
    "    lemmatized_text = ' '.join([lemmatizer.lemmatize(word) for word in text.split()])\n",
    "    lemmatized_texts.append(lemmatized_text)\n",
    "combined_df['text'] = lemmatized_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>grandma grandpa travel ban state welcome u cable</td>\n",
       "      <td>washington reuters grandparent u citizen six m...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>July 17, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lexisnexis withdrew two product chinese market</td>\n",
       "      <td>london reuters lexisnexis provider legal regul...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>August 22, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>white house budget chief expects delay hitting...</td>\n",
       "      <td>washington reuters white house budget chief mi...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>February 28, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>indian prime minister modi visit washington ye...</td>\n",
       "      <td>washington reuters u president donald trump sp...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>March 28, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>list company caved leftistspulled ad hannity s...</td>\n",
       "      <td>company including carscom peloton leesa sleep ...</td>\n",
       "      <td>left-news</td>\n",
       "      <td>May 25, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0   grandma grandpa travel ban state welcome u cable   \n",
       "1     lexisnexis withdrew two product chinese market   \n",
       "2  white house budget chief expects delay hitting...   \n",
       "3  indian prime minister modi visit washington ye...   \n",
       "4  list company caved leftistspulled ad hannity s...   \n",
       "\n",
       "                                                text       subject  \\\n",
       "0  washington reuters grandparent u citizen six m...  politicsNews   \n",
       "1  london reuters lexisnexis provider legal regul...     worldnews   \n",
       "2  washington reuters white house budget chief mi...  politicsNews   \n",
       "3  washington reuters u president donald trump sp...  politicsNews   \n",
       "4  company including carscom peloton leesa sleep ...     left-news   \n",
       "\n",
       "                 date  label  \n",
       "0      July 17, 2017       0  \n",
       "1    August 22, 2017       0  \n",
       "2  February 28, 2017       0  \n",
       "3     March 28, 2017       0  \n",
       "4        May 25, 2017      1  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lemmatize title\n",
    "lemmatized_titles = []\n",
    "for title in combined_df['title']:\n",
    "    lemmatized_title = ' '.join([lemmatizer.lemmatize(word) for word in title.split()])\n",
    "    lemmatized_titles.append(lemmatized_title)\n",
    "combined_df['title'] = lemmatized_titles\n",
    "\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Building\n",
    "1) Machine Learning model\n",
    "   - Random Forest\n",
    "2) Deep Learning model\n",
    "   - LSTM\n",
    "3) Convolutional Neural Network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the title, text, and subject columns into a single column\n",
    "combined_df['combined_text'] = combined_df['title'] + ' ' + combined_df['text'] + ' ' + combined_df['subject']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text preprocessing and TF-IDF vectorization\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_df=0.7)\n",
    "X = vectorizer.fit_transform(combined_df['combined_text'])\n",
    "y = combined_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Random Forest model\u001b[39;00m\n\u001b[0;32m      2\u001b[0m rf_model \u001b[38;5;241m=\u001b[39m RandomForestClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mrf_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_forest.py:456\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    445\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    448\u001b[0m ]\n\u001b[0;32m    450\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 456\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    462\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    463\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    464\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    465\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    466\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    467\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    468\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    469\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    470\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    471\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    472\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    473\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_forest.py:188\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    186\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[1;32m--> 188\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    190\u001b[0m     tree\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\tree\\_classes.py:959\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    929\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    930\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    931\u001b[0m \n\u001b[0;32m    932\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    956\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    957\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 959\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    961\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    962\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    963\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    964\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    965\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\tree\\_classes.py:443\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    433\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    434\u001b[0m         splitter,\n\u001b[0;32m    435\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    440\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    441\u001b[0m     )\n\u001b[1;32m--> 443\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.9948775055679288\n"
     ]
    }
   ],
   "source": [
    "y_pred_rf = rf_model.predict(X_test)\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      4202\n",
      "           1       1.00      0.99      1.00      4778\n",
      "\n",
      "    accuracy                           0.99      8980\n",
      "   macro avg       0.99      0.99      0.99      8980\n",
      "weighted avg       0.99      0.99      0.99      8980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text\n",
    "max_words = 5000\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(combined_df['combined_text'])\n",
    "X = tokenizer.texts_to_sequences(combined_df['combined_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad the sequences\n",
    "max_len = 100\n",
    "X = pad_sequences(X, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = combined_df['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LSTM Model \n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words, 128, input_length=max_len))\n",
    "model.add(LSTM(64, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1123/1123 - 144s - loss: 0.0240 - accuracy: 0.9937 - val_loss: 8.6710e-05 - val_accuracy: 1.0000 - 144s/epoch - 128ms/step\n",
      "Epoch 2/5\n",
      "1123/1123 - 138s - loss: 3.1778e-05 - accuracy: 1.0000 - val_loss: 4.0546e-05 - val_accuracy: 1.0000 - 138s/epoch - 123ms/step\n",
      "Epoch 3/5\n",
      "1123/1123 - 139s - loss: 1.0492e-05 - accuracy: 1.0000 - val_loss: 1.8659e-05 - val_accuracy: 1.0000 - 139s/epoch - 124ms/step\n",
      "Epoch 4/5\n",
      "1123/1123 - 131s - loss: 5.4758e-06 - accuracy: 1.0000 - val_loss: 1.8357e-05 - val_accuracy: 1.0000 - 131s/epoch - 117ms/step\n",
      "Epoch 5/5\n",
      "1123/1123 - 132s - loss: 2.4780e-06 - accuracy: 1.0000 - val_loss: 6.9744e-06 - val_accuracy: 1.0000 - 132s/epoch - 117ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x272a2299850>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=32,\n",
    "          epochs=5,\n",
    "          validation_data=(X_test, y_test),\n",
    "          verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281/281 [==============================] - 4s 13ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM Model Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"LSTM Model Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      4202\n",
      "           1       1.00      1.00      1.00      4778\n",
      "\n",
      "    accuracy                           1.00      8980\n",
      "   macro avg       1.00      1.00      1.00      8980\n",
      "weighted avg       1.00      1.00      1.00      8980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(combined_df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN Model\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words, 128, input_length=max_len))\n",
    "model.add(Conv1D(128, 5, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=4))\n",
    "model.add(Conv1D(128, 5, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1123/1123 - 39s - loss: 0.0491 - accuracy: 0.9727 - val_loss: 4.3163e-05 - val_accuracy: 1.0000 - 39s/epoch - 35ms/step\n",
      "Epoch 2/5\n",
      "1123/1123 - 25s - loss: 7.3830e-06 - accuracy: 1.0000 - val_loss: 1.0454e-06 - val_accuracy: 1.0000 - 25s/epoch - 23ms/step\n",
      "Epoch 3/5\n",
      "1123/1123 - 26s - loss: 1.6799e-06 - accuracy: 1.0000 - val_loss: 5.2580e-07 - val_accuracy: 1.0000 - 26s/epoch - 23ms/step\n",
      "Epoch 4/5\n",
      "1123/1123 - 37s - loss: 9.2485e-07 - accuracy: 1.0000 - val_loss: 2.6016e-07 - val_accuracy: 1.0000 - 37s/epoch - 33ms/step\n",
      "Epoch 5/5\n",
      "1123/1123 - 26s - loss: 6.9820e-07 - accuracy: 1.0000 - val_loss: 1.2794e-07 - val_accuracy: 1.0000 - 26s/epoch - 24ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1a8dd316c90>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=5, validation_data=(X_test, y_test), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281/281 [==============================] - 3s 9ms/step\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "#y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        True       1.00      1.00      1.00      4314\n",
      "        Fake       1.00      1.00      1.00      4666\n",
      "\n",
      "    accuracy                           1.00      8980\n",
      "   macro avg       1.00      1.00      1.00      8980\n",
      "weighted avg       1.00      1.00      1.00      8980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print classification report\n",
    "target_names = ['True', 'Fake']\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
