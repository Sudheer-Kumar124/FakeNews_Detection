{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model-3 - BERT based Modelling\n",
    "\n",
    "**BERT (Bidirectional Encoder Representations from Transformers)**\n",
    " is a deep learning model developed by Google for natural language processing tasks. BERT is designed to understand the context of words in search queries. It does this by processing words in both directions (left-to-right and right-to-left) using a transformer-based architecture. This bidirectional approach enables BERT to capture the meaning of words based on their context within a sentence, making it highly effective for tasks like question answering, sentiment analysis, and language translation. BERT-based models have significantly improved the performance of various NLP applications due to their ability to understand context more accurately than previous models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nRT80JWTpHhd"
   },
   "source": [
    "## Data Preprocessing\n",
    "Data preprocessing transforms raw data into a clean and usable format by handling missing values, outliers, and ensuring consistent data scales through normalization or standardization. It also includes feature extraction and selection to enhance dataset quality. This step is essential for efficient and accurate data analysis or machine learning model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "gExiGR93vMaj"
   },
   "outputs": [],
   "source": [
    "# importing all the necessary libraries\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from scipy.sparse import hstack\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 851
    },
    "id": "MVfzr04EwGpL",
    "outputId": "c6d24acd-2828-406f-9131-c645108f50de"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>title</th>\n",
       "      <th>location</th>\n",
       "      <th>department</th>\n",
       "      <th>salary_range</th>\n",
       "      <th>company_profile</th>\n",
       "      <th>description</th>\n",
       "      <th>requirements</th>\n",
       "      <th>benefits</th>\n",
       "      <th>telecommuting</th>\n",
       "      <th>has_company_logo</th>\n",
       "      <th>has_questions</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>required_experience</th>\n",
       "      <th>required_education</th>\n",
       "      <th>industry</th>\n",
       "      <th>function</th>\n",
       "      <th>fraudulent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Marketing Intern</td>\n",
       "      <td>US, NY, New York</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We're Food52, and we've created a groundbreaki...</td>\n",
       "      <td>Food52, a fast-growing, James Beard Award-winn...</td>\n",
       "      <td>Experience with content management systems a m...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Other</td>\n",
       "      <td>Internship</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Customer Service - Cloud Video Production</td>\n",
       "      <td>NZ, , Auckland</td>\n",
       "      <td>Success</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90 Seconds, the worlds Cloud Video Production ...</td>\n",
       "      <td>Organised - Focused - Vibrant - Awesome!Do you...</td>\n",
       "      <td>What we expect from you:Your key responsibilit...</td>\n",
       "      <td>What you will get from usThrough being part of...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Marketing and Advertising</td>\n",
       "      <td>Customer Service</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Commissioning Machinery Assistant (CMA)</td>\n",
       "      <td>US, IA, Wever</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Valor Services provides Workforce Solutions th...</td>\n",
       "      <td>Our client, located in Houston, is actively se...</td>\n",
       "      <td>Implement pre-commissioning and commissioning ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Account Executive - Washington DC</td>\n",
       "      <td>US, DC, Washington</td>\n",
       "      <td>Sales</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our passion for improving quality of life thro...</td>\n",
       "      <td>THE COMPANY: ESRI – Environmental Systems Rese...</td>\n",
       "      <td>EDUCATION: Bachelor’s or Master’s in GIS, busi...</td>\n",
       "      <td>Our culture is anything but corporate—we have ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>Bachelor's Degree</td>\n",
       "      <td>Computer Software</td>\n",
       "      <td>Sales</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Bill Review Manager</td>\n",
       "      <td>US, FL, Fort Worth</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SpotSource Solutions LLC is a Global Human Cap...</td>\n",
       "      <td>JOB TITLE: Itemization Review ManagerLOCATION:...</td>\n",
       "      <td>QUALIFICATIONS:RN license in the State of Texa...</td>\n",
       "      <td>Full Benefits Offered</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>Bachelor's Degree</td>\n",
       "      <td>Hospital &amp; Health Care</td>\n",
       "      <td>Health Care Provider</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Accounting Clerk</td>\n",
       "      <td>US, MD,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Job OverviewApex is an environmental consultin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Head of Content (m/f)</td>\n",
       "      <td>DE, BE, Berlin</td>\n",
       "      <td>ANDROIDPIT</td>\n",
       "      <td>20000-28000</td>\n",
       "      <td>Founded in 2009, the Fonpit AG rose with its i...</td>\n",
       "      <td>Your Responsibilities: Manage the English-spea...</td>\n",
       "      <td>Your Know-How:                                ...</td>\n",
       "      <td>Your Benefits: Being part of a fast-growing co...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>Master's Degree</td>\n",
       "      <td>Online Media</td>\n",
       "      <td>Management</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Lead Guest Service Specialist</td>\n",
       "      <td>US, CA, San Francisco</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Airenvy’s mission is to provide lucrative yet ...</td>\n",
       "      <td>Who is Airenvy?Hey there! We are seasoned entr...</td>\n",
       "      <td>Experience with CRM software, live chat, and p...</td>\n",
       "      <td>Competitive Pay. You'll be able to eat steak e...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>HP BSM SME</td>\n",
       "      <td>US, FL, Pensacola</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Solutions3 is a woman-owned small business who...</td>\n",
       "      <td>Implementation/Configuration/Testing/Training ...</td>\n",
       "      <td>MUST BE A US CITIZEN.An active TS/SCI clearanc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Associate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Information Technology and Services</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Customer Service Associate - Part Time</td>\n",
       "      <td>US, AZ, Phoenix</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Novitex Enterprise Solutions, formerly Pitney ...</td>\n",
       "      <td>The Customer Service Associate will be based i...</td>\n",
       "      <td>Minimum Requirements:Minimum of 6 months custo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Part-time</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>High School or equivalent</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>Customer Service</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   job_id                                      title               location  \\\n",
       "0       1                           Marketing Intern       US, NY, New York   \n",
       "1       2  Customer Service - Cloud Video Production         NZ, , Auckland   \n",
       "2       3    Commissioning Machinery Assistant (CMA)          US, IA, Wever   \n",
       "3       4          Account Executive - Washington DC     US, DC, Washington   \n",
       "4       5                        Bill Review Manager     US, FL, Fort Worth   \n",
       "5       6                           Accounting Clerk               US, MD,    \n",
       "6       7                      Head of Content (m/f)         DE, BE, Berlin   \n",
       "7       8           Lead Guest Service Specialist     US, CA, San Francisco   \n",
       "8       9                                 HP BSM SME      US, FL, Pensacola   \n",
       "9      10    Customer Service Associate - Part Time         US, AZ, Phoenix   \n",
       "\n",
       "   department salary_range                                    company_profile  \\\n",
       "0   Marketing          NaN  We're Food52, and we've created a groundbreaki...   \n",
       "1     Success          NaN  90 Seconds, the worlds Cloud Video Production ...   \n",
       "2         NaN          NaN  Valor Services provides Workforce Solutions th...   \n",
       "3       Sales          NaN  Our passion for improving quality of life thro...   \n",
       "4         NaN          NaN  SpotSource Solutions LLC is a Global Human Cap...   \n",
       "5         NaN          NaN                                                NaN   \n",
       "6  ANDROIDPIT  20000-28000  Founded in 2009, the Fonpit AG rose with its i...   \n",
       "7         NaN          NaN  Airenvy’s mission is to provide lucrative yet ...   \n",
       "8         NaN          NaN  Solutions3 is a woman-owned small business who...   \n",
       "9         NaN          NaN  Novitex Enterprise Solutions, formerly Pitney ...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Food52, a fast-growing, James Beard Award-winn...   \n",
       "1  Organised - Focused - Vibrant - Awesome!Do you...   \n",
       "2  Our client, located in Houston, is actively se...   \n",
       "3  THE COMPANY: ESRI – Environmental Systems Rese...   \n",
       "4  JOB TITLE: Itemization Review ManagerLOCATION:...   \n",
       "5  Job OverviewApex is an environmental consultin...   \n",
       "6  Your Responsibilities: Manage the English-spea...   \n",
       "7  Who is Airenvy?Hey there! We are seasoned entr...   \n",
       "8  Implementation/Configuration/Testing/Training ...   \n",
       "9  The Customer Service Associate will be based i...   \n",
       "\n",
       "                                        requirements  \\\n",
       "0  Experience with content management systems a m...   \n",
       "1  What we expect from you:Your key responsibilit...   \n",
       "2  Implement pre-commissioning and commissioning ...   \n",
       "3  EDUCATION: Bachelor’s or Master’s in GIS, busi...   \n",
       "4  QUALIFICATIONS:RN license in the State of Texa...   \n",
       "5                                                NaN   \n",
       "6  Your Know-How:                                ...   \n",
       "7  Experience with CRM software, live chat, and p...   \n",
       "8  MUST BE A US CITIZEN.An active TS/SCI clearanc...   \n",
       "9  Minimum Requirements:Minimum of 6 months custo...   \n",
       "\n",
       "                                            benefits  telecommuting  \\\n",
       "0                                                NaN              0   \n",
       "1  What you will get from usThrough being part of...              0   \n",
       "2                                                NaN              0   \n",
       "3  Our culture is anything but corporate—we have ...              0   \n",
       "4                              Full Benefits Offered              0   \n",
       "5                                                NaN              0   \n",
       "6  Your Benefits: Being part of a fast-growing co...              0   \n",
       "7  Competitive Pay. You'll be able to eat steak e...              0   \n",
       "8                                                NaN              0   \n",
       "9                                                NaN              0   \n",
       "\n",
       "   has_company_logo  has_questions employment_type required_experience  \\\n",
       "0                 1              0           Other          Internship   \n",
       "1                 1              0       Full-time      Not Applicable   \n",
       "2                 1              0             NaN                 NaN   \n",
       "3                 1              0       Full-time    Mid-Senior level   \n",
       "4                 1              1       Full-time    Mid-Senior level   \n",
       "5                 0              0             NaN                 NaN   \n",
       "6                 1              1       Full-time    Mid-Senior level   \n",
       "7                 1              1             NaN                 NaN   \n",
       "8                 1              1       Full-time           Associate   \n",
       "9                 1              0       Part-time         Entry level   \n",
       "\n",
       "          required_education                             industry  \\\n",
       "0                        NaN                                  NaN   \n",
       "1                        NaN            Marketing and Advertising   \n",
       "2                        NaN                                  NaN   \n",
       "3          Bachelor's Degree                    Computer Software   \n",
       "4          Bachelor's Degree               Hospital & Health Care   \n",
       "5                        NaN                                  NaN   \n",
       "6            Master's Degree                         Online Media   \n",
       "7                        NaN                                  NaN   \n",
       "8                        NaN  Information Technology and Services   \n",
       "9  High School or equivalent                   Financial Services   \n",
       "\n",
       "               function  fraudulent  \n",
       "0             Marketing           0  \n",
       "1      Customer Service           0  \n",
       "2                   NaN           0  \n",
       "3                 Sales           0  \n",
       "4  Health Care Provider           0  \n",
       "5                   NaN           0  \n",
       "6            Management           0  \n",
       "7                   NaN           0  \n",
       "8                   NaN           0  \n",
       "9      Customer Service           0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading and displaying the first 10 rows of the CSV file\n",
    "df=pd.read_csv('fake_job_postings.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "VKzDCsrhwTTn"
   },
   "outputs": [],
   "source": [
    "# Fill missing values in text columns with empty strings\n",
    "text_columns = ['description', 'requirements', 'company_profile', 'title', 'location', 'department', 'salary_range', 'employment_type', 'required_experience', 'required_education', 'industry', 'function']\n",
    "df[text_columns] = df[text_columns].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "Z0JSrJ0PwZ97"
   },
   "outputs": [],
   "source": [
    "# Combine text columns into a single column for vectorization\n",
    "df['combined_text'] = df[text_columns].apply(lambda x: ' '.join(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "aLSXVoy7wf0O"
   },
   "outputs": [],
   "source": [
    "# Simplified text preprocessing\n",
    "df['combined_text'] = df['combined_text'].str.lower()\n",
    "df['combined_text'] = df['combined_text'].apply(lambda x: re.sub(r'http\\S+|www\\S+|https\\S+', '', x))\n",
    "df['combined_text'] = df['combined_text'].str.replace('\\n', ' ')\n",
    "df['combined_text'] = df['combined_text'].apply(lambda x: re.sub(r'\\w*\\d\\w*', '', x))\n",
    "df['combined_text'] = df['combined_text'].str.strip()\n",
    "df['combined_text'] = df['combined_text'].apply(lambda x: re.sub(' +', ' ', x))\n",
    "df['combined_text'] = df['combined_text'].apply(lambda x: re.sub(r'[^a-zA-Z\\s]', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "SeA9Lm5cwmf8"
   },
   "outputs": [],
   "source": [
    "# Tokenize the text data\n",
    "tokenizer = Tokenizer(num_words=5000)  # Limit to the top 5000 words\n",
    "tokenizer.fit_on_texts(df['combined_text'])\n",
    "X_text = tokenizer.texts_to_sequences(df['combined_text'])\n",
    "\n",
    "# Pad sequences to the same length\n",
    "max_length = 100\n",
    "X_text_padded = pad_sequences(X_text, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "CJJ8RfuFwwb8"
   },
   "outputs": [],
   "source": [
    "# List of non-text columns to be used as features\n",
    "non_text_columns = ['telecommuting', 'has_company_logo', 'has_questions', 'location', 'department', 'salary_range', 'employment_type', 'required_experience', 'required_education', 'industry', 'function']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "k2MuIeTxw6e-"
   },
   "outputs": [],
   "source": [
    "# Fill missing values in non-text columns with a placeholder\n",
    "df[non_text_columns] = df[non_text_columns].fillna('missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "gpCGEczew9ct"
   },
   "outputs": [],
   "source": [
    "# OneHotEncode the categorical non-text columns\n",
    "categorical_columns = ['location', 'department', 'salary_range', 'employment_type', 'required_experience', 'required_education', 'industry', 'function']\n",
    "encoder = OneHotEncoder()\n",
    "X_non_text_encoded = encoder.fit_transform(df[categorical_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "vSr66rg3xApx"
   },
   "outputs": [],
   "source": [
    "# Scale non-categorical non-text columns\n",
    "scaler = StandardScaler()\n",
    "X_non_text_scaled = scaler.fit_transform(df[['telecommuting', 'has_company_logo', 'has_questions']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "2rcV4jerxEnu"
   },
   "outputs": [],
   "source": [
    "# Combine non-categorical and categorical features\n",
    "from scipy.sparse import hstack\n",
    "X_non_text = hstack([X_non_text_encoded, X_non_text_scaled]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "kKzxMfcMxJEM"
   },
   "outputs": [],
   "source": [
    "# Combine the text and non-text features\n",
    "X_combined = np.hstack((X_text_padded, X_non_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9_k4q9K9poz1"
   },
   "source": [
    "## Model Building\n",
    "\n",
    "Building a model with BERT involves several key steps. First, text data is tokenized using the BERT tokenizer. Then, a pre-trained BERT model, such as `bert-base-uncased`, is selected. To tailor the model for a specific task, a task-specific layer is added on top. The model is fine-tuned on the dataset, typically using a smaller learning rate and fewer epochs compared to training from scratch. During training, appropriate loss functions and optimizers are used. The model’s performance is evaluated using metrics like accuracy or F1 score. Hugging Face's Transformers library makes this process efficient by providing tools for implementation and fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "pc4klgUpxT7k"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "Atm-bGJYxzFp"
   },
   "outputs": [],
   "source": [
    "# Split the data into training, testing, and validation sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X_combined, df['fraudulent'], test_size=0.3, random_state=42\n",
    ")\n",
    "X_test, X_val, y_test, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.33, random_state=42\n",
    ")  # 0.33 * 0.3 = 0.10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approch-\n",
    "The overall approach for preparing text data for BERT-based modeling can be broken down into several steps:\n",
    "\n",
    "**Load the Pre-trained BERT Tokenizer**:\n",
    "Use a pre-trained BERT tokenizer to tokenize and preprocess the text data. The tokenizer converts text into tokens that the BERT model can understand.\n",
    "\n",
    "**Tokenization Function**:\n",
    "Define a function to tokenize the text data. This function extracts the text data from the input, tokenizes it, and ensures that all sequences are of uniform length by padding and truncating them as necessary.\n",
    "\n",
    "**Apply the Tokenization**:\n",
    "Use the tokenization function to process the training, validation, and test datasets. This converts the raw text data into tokenized format, ready for input into the BERT model.\n",
    "\n",
    "# Benefits of this Approach\n",
    "\n",
    "**Efficiency**:\n",
    "Using a pre-trained tokenizer and model like BERT significantly reduces the computational resources and time required compared to training a model from scratch.\n",
    "\n",
    "**Consistency**:\n",
    "Padding and truncation ensure that all input sequences are of uniform length, which is crucial for efficient batch processing.\n",
    "\n",
    "**Compatibility**:\n",
    "Converting the tokenized data to PyTorch tensors ensures compatibility with PyTorch-based BERT models, facilitating seamless integration into the training and evaluation pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YKu1IW8GzFd9",
    "outputId": "82ad1662-5f93-47a5-da10-761d0ea4ecc3"
   },
   "outputs": [],
   "source": [
    "# Load pre-trained BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenize the input data\n",
    "def tokenize_data(texts):\n",
    "    # Assuming the first column of your arrays contains the text data\n",
    "    return tokenizer([str(row[0]) for row in texts], padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "train_encodings = tokenize_data(X_train.tolist())\n",
    "val_encodings = tokenize_data(X_val.tolist())\n",
    "test_encodings = tokenize_data(X_test.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "FUOPMiZVyOGQ"
   },
   "outputs": [],
   "source": [
    "# Convert the labels to tensors with Float type\n",
    "train_labels = torch.tensor(y_train.values, dtype=torch.float32)\n",
    "val_labels = torch.tensor(y_val.values, dtype=torch.float32)\n",
    "test_labels = torch.tensor(y_test.values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "YCuyJVSvyZjR"
   },
   "outputs": [],
   "source": [
    "# Define a Dataset class\n",
    "class FraudDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = self.labels[idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = FraudDataset(train_encodings, train_labels)\n",
    "val_dataset = FraudDataset(val_encodings, val_labels)\n",
    "test_dataset = FraudDataset(test_encodings, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uyjmbOXFycZW",
    "outputId": "2a2b6e1f-d915-4d39-de45-161da9c5b6a0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained BERT model with regression head\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nn5zQL9eyfhS",
    "outputId": "37c90ec8-6fed-4eae-b33c-3a4ed5ff8170"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benefits of Using Trainer\n",
    "Simplifies the Training Process: The Trainer class abstracts many of the complex details involved in training a model, making it easier to implement and manage.\n",
    "Integrated Evaluation: By providing both training and evaluation datasets, the Trainer can automatically evaluate the model's performance during training.\n",
    "Configuration Management: The training_args parameter allows for comprehensive configuration of the training process, including advanced features like gradient accumulation and mixed precision training.\n",
    "Built-in Features: The Trainer includes features like logging, saving checkpoints, and early stopping, which are essential for robust model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 325
    },
    "id": "3hZNNGtK5Tkr",
    "outputId": "b7068283-16a0-4935-8fea-6d60ab025ee9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4695' max='4695' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4695/4695 2:26:01, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.024500</td>\n",
       "      <td>0.055883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.056545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.024300</td>\n",
       "      <td>0.053403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4695, training_loss=0.047395093910023174, metrics={'train_runtime': 8764.1948, 'train_samples_per_second': 4.284, 'train_steps_per_second': 0.536, 'total_flos': 135067258654776.0, 'train_loss': 0.047395093910023174, 'epoch': 3.0})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XZ05g6-hpyBQ"
   },
   "source": [
    "## Model Evaluation\n",
    "Model evaluation involves assessing a trained model's performance using various metrics to determine its effectiveness and generalization ability. Common metrics for classification tasks include accuracy, precision, recall, F1 score, and AUC-ROC, while regression tasks often use mean squared error (MSE), mean absolute error (MAE), and R-squared. The evaluation process typically includes splitting the data into training and testing sets, training the model on the training set, and evaluating it on the test set to ensure the model performs well on unseen data. Cross-validation can also be used for more robust evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "tZMtbLlZJoJf",
    "outputId": "45c5f59b-f6ce-45be-f039-8789e0a724c6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss (MSE): 0.04579808935523033\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "eval_result = trainer.evaluate(eval_dataset=test_dataset)\n",
    "print(f\"Test Loss (MSE): {eval_result['eval_loss']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "O8AcBKA11DiG",
    "outputId": "125eaa25-460e-4185-ca0a-3568a26e39db"
   },
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "predictions = trainer.predict(test_dataset)\n",
    "y_pred = predictions.predictions.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eDPeYFf81yIA",
    "outputId": "c2f89cd5-7b9c-4fbb-e18a-381f22198a9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 0.07158705714875933\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f'Mean Absolute Error (MAE): {mae}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "83grTNMEqKlR"
   },
   "source": [
    "## Conclusion\n",
    "The model exhibits a Mean Squared Error (MSE) of 0.0456 and a Mean Absolute Error (MAE) of 0.0805 on the test data, indicating that it performs well with a relatively low level of prediction error. These metrics suggest that the model is effective at predicting values close to the actual targets, demonstrating good accuracy for the regression task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AR9wWmeRrzde"
   },
   "source": [
    "# Output Analysis\n",
    "\n",
    "### BERT-Based Model\n",
    "- **Test Loss (MSE)**: 0.0456\n",
    "- **Mean Absolute Error (MAE)**: 0.0805\n",
    "\n",
    "### Comparison:\n",
    "\n",
    "3. **BERT-Based Model**:\n",
    "   - **Plus**: Comparable performance to LSTM with slightly higher MSE and MAE.\n",
    "   - **minus**: Similar to LSTM, BERT models are computationally expensive and complex.\n",
    "   - **suitable scenario**: Text data or situations where contextual understanding is important.\n",
    "\n",
    "### Recommendation:\n",
    "\n",
    "If achieving high accuracy across all classes is paramount, particularly with a noticeable class imbalance, **Logistic Regression** remains a strong contender, despite its tendency to underperform on minority classes.\n",
    "\n",
    "In scenarios involving sequential or time-series data, where capturing intricate dependencies is crucial, opting for an **LSTM Model** would be advantageous.\n",
    "\n",
    "When dealing with textual data or situations requiring nuanced understanding of context, leveraging a **BERT-Based Model** proves highly effective.\n",
    "\n",
    "When analyzing metrics, the Logistic Regression model consistently demonstrates superior performance across accuracy and weighted averages. However, depending on the complexity and specificity of the task at hand, either the LSTM or BERT model might offer more suitable solutions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P_csLL8H2aUw"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
