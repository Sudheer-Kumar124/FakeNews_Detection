{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc82c3e0-e728-4569-91a9-d16f8b9bdbc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "Best Parameters: {'C': 10.0, 'solver': 'liblinear'}\n",
      "Test Accuracy: 0.98\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      3403\n",
      "           1       0.94      0.62      0.75       173\n",
      "\n",
      "    accuracy                           0.98      3576\n",
      "   macro avg       0.96      0.81      0.87      3576\n",
      "weighted avg       0.98      0.98      0.98      3576\n",
      "\n",
      "Test Confusion Matrix:\n",
      "[[3396    7]\n",
      " [  65  108]]\n",
      "\n",
      "Validation Accuracy: 0.98\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      1701\n",
      "           1       0.93      0.57      0.71        87\n",
      "\n",
      "    accuracy                           0.98      1788\n",
      "   macro avg       0.95      0.79      0.85      1788\n",
      "weighted avg       0.98      0.98      0.97      1788\n",
      "\n",
      "Validation Confusion Matrix:\n",
      "[[1697    4]\n",
      " [  37   50]]\n",
      "\n",
      "Training Accuracy: 0.99\n",
      "Training Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00     11910\n",
      "           1       1.00      0.87      0.93       605\n",
      "\n",
      "    accuracy                           0.99     12515\n",
      "   macro avg       1.00      0.93      0.96     12515\n",
      "weighted avg       0.99      0.99      0.99     12515\n",
      "\n",
      "Training Confusion Matrix:\n",
      "[[11909     1]\n",
      " [   79   526]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Load the preprocessed data from a CSV file\n",
    "df = pd.read_csv('preprocesssed_data.csv')\n",
    "\n",
    "# Ensure your CSV file has at least 'text' and 'label' columns\n",
    "if 'text' not in df.columns or 'label' not in df.columns:\n",
    "    raise ValueError(\"The input CSV file must contain 'text' and 'label' columns.\")\n",
    "\n",
    "# Split the data into training (70%) and remaining (30%)\n",
    "train_data, remaining_data = train_test_split(df, train_size=0.7, random_state=42, stratify=df['label'])\n",
    "\n",
    "# Split the remaining data into testing (20% of total) and validation (10% of total)\n",
    "test_data, val_data = train_test_split(remaining_data, test_size=1/3, random_state=42, stratify=remaining_data['label'])\n",
    "\n",
    "# Vectorize the text data using TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train = tfidf_vectorizer.fit_transform(train_data['text'])\n",
    "X_test = tfidf_vectorizer.transform(test_data['text'])\n",
    "X_val = tfidf_vectorizer.transform(val_data['text'])\n",
    "\n",
    "# Get the labels\n",
    "y_train = train_data['label']\n",
    "y_test = test_data['label']\n",
    "y_val = val_data['label']\n",
    "\n",
    "# Initialize the Logistic Regression model\n",
    "log_reg_model = LogisticRegression(random_state=42)\n",
    "\n",
    "# Define the hyperparameters and their values for grid search\n",
    "param_grid = {\n",
    "    'C': [0.1, 1.0, 10.0],\n",
    "    'solver': ['liblinear', 'lbfgs']\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=log_reg_model, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2, scoring='accuracy')\n",
    "\n",
    "# Fit the model with GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best estimator\n",
    "best_log_reg_model = grid_search.best_estimator_\n",
    "\n",
    "# Predict on the test data\n",
    "y_test_pred = best_log_reg_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_report = classification_report(y_test, y_test_pred)\n",
    "test_conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "# Print the performance metrics for the test data\n",
    "print(f'Best Parameters: {grid_search.best_params_}')\n",
    "print(f'Test Accuracy: {test_accuracy:.2f}')\n",
    "print('Test Classification Report:')\n",
    "print(test_report)\n",
    "print('Test Confusion Matrix:')\n",
    "print(test_conf_matrix)\n",
    "\n",
    "# Predict on the validation data\n",
    "y_val_pred = best_log_reg_model.predict(X_val)\n",
    "\n",
    "# Evaluate the model on the validation data\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "val_report = classification_report(y_val, y_val_pred)\n",
    "val_conf_matrix = confusion_matrix(y_val, y_val_pred)\n",
    "\n",
    "# Print the performance metrics for the validation data\n",
    "print(f'\\nValidation Accuracy: {val_accuracy:.2f}')\n",
    "print('Validation Classification Report:')\n",
    "print(val_report)\n",
    "print('Validation Confusion Matrix:')\n",
    "print(val_conf_matrix)\n",
    "\n",
    "# Evaluate on the training data to check for overfitting\n",
    "y_train_pred = best_log_reg_model.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "train_report = classification_report(y_train, y_train_pred)\n",
    "train_conf_matrix = confusion_matrix(y_train, y_train_pred)\n",
    "\n",
    "# Print the performance metrics for the training data\n",
    "print(f'\\nTraining Accuracy: {train_accuracy:.2f}')\n",
    "print('Training Classification Report:')\n",
    "print(train_report)\n",
    "print('Training Confusion Matrix:')\n",
    "print(train_conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2c5ad74-9f66-4135-9001-404080b7acc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9970 - loss: 0.0131\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9774 - loss: 0.1043\n",
      "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9973 - loss: 0.0127\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9736 - loss: 0.1028\n",
      "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9963 - loss: 0.0139\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9678 - loss: 0.1216\n",
      "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9951 - loss: 0.0178\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9630 - loss: 0.1165\n",
      "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9976 - loss: 0.0104\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9772 - loss: 0.0997\n",
      "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9975 - loss: 0.0101\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9777 - loss: 0.1002\n",
      "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9984 - loss: 0.0091\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9786 - loss: 0.1051\n",
      "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.9946 - loss: 0.0199\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9702 - loss: 0.1103\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step\n",
      "LSTM Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.98      0.99      0.98      3394\n",
      "        real       0.77      0.58      0.66       182\n",
      "\n",
      "    accuracy                           0.97      3576\n",
      "   macro avg       0.87      0.78      0.82      3576\n",
      "weighted avg       0.97      0.97      0.97      3576\n",
      "\n",
      "Training Accuracy: 0.9954553246498108\n",
      "Validation Accuracy: 0.9671443700790405\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9706 - loss: 0.1519\n",
      "Test Accuracy: 0.9695190191268921\n",
      "Confusion Matrix:\n",
      "[[3362   32]\n",
      " [  77  105]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Load the preprocessed CSV file\n",
    "df = pd.read_csv('preprocesssed_data.csv')\n",
    "\n",
    "# Split the data into training, validation, and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['label'], test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert the labels to numerical values\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_val = le.transform(y_val)\n",
    "y_test = le.transform(y_test)\n",
    "\n",
    "# Tokenize the text data\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "# Convert text data to sequences\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_val = tokenizer.texts_to_sequences(X_val)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "# Pad the sequences to have the same length\n",
    "max_length = 200\n",
    "padded_train = pad_sequences(X_train, maxlen=max_length)\n",
    "padded_val = pad_sequences(X_val, maxlen=max_length)\n",
    "padded_test = pad_sequences(X_test, maxlen=max_length)\n",
    "\n",
    "# Define the LSTM model\n",
    "def lstm_model(lstm_units, dropout, batch_size):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=5000, output_dim=128))\n",
    "    model.add(LSTM(lstm_units, dropout=dropout))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Define the hyperparameters for grid search\n",
    "lstm_hyperparameters = {\n",
    "    'lstm_units': [32, 64],\n",
    "    'dropout': [0.1, 0.2],\n",
    "    'batch_size': [32, 64]\n",
    "}\n",
    "\n",
    "# Perform grid search for LSTM model\n",
    "best_lstm_model = None\n",
    "best_lstm_accuracy = 0\n",
    "for lstm_units in lstm_hyperparameters['lstm_units']:\n",
    "    for dropout in lstm_hyperparameters['dropout']:\n",
    "        for batch_size in lstm_hyperparameters['batch_size']:\n",
    "            model = lstm_model(lstm_units, dropout, batch_size)\n",
    "            model.fit(padded_train, y_train, epochs=5, batch_size=batch_size, validation_data=(padded_val, y_val), verbose=0)\n",
    "            train_accuracy = model.evaluate(padded_train, y_train)[1]\n",
    "            val_accuracy = model.evaluate(padded_val, y_val)[1]\n",
    "            if val_accuracy > best_lstm_accuracy:\n",
    "                best_lstm_model = model\n",
    "                best_lstm_accuracy = val_accuracy\n",
    "\n",
    "# Generate classification report for the best LSTM model\n",
    "y_pred_lstm = best_lstm_model.predict(padded_test)\n",
    "y_pred_lstm = (y_pred_lstm > 0.5).astype(int)\n",
    "print(\"LSTM Model Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_lstm, target_names=['fake', 'real'])) \n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "print(\"Validation Accuracy:\", val_accuracy)\n",
    "print(\"Test Accuracy:\", best_lstm_model.evaluate(padded_test, y_test)[1])\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_lstm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2eaa8045-27fc-4cec-8471-d5c2907f77a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.96      1.00      0.98      3394\n",
      "        real       1.00      0.14      0.25       182\n",
      "\n",
      "    accuracy                           0.96      3576\n",
      "   macro avg       0.98      0.57      0.61      3576\n",
      "weighted avg       0.96      0.96      0.94      3576\n",
      "\n",
      "Training Accuracy: 0.9590980597797588\n",
      "Validation Accuracy: 0.9542118140510311\n",
      "Test Accuracy: 0.9563758389261745\n",
      "Confusion Matrix:\n",
      "[[3394    0]\n",
      " [ 156   26]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Load the preprocessed CSV file\n",
    "df = pd.read_csv('preprocesssed_data.csv')\n",
    "\n",
    "# Split the data into training, validation, and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['label'], test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert the text data to numerical features using CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_val_vectorized = vectorizer.transform(X_val)\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "# Define the hyperparameters for grid search\n",
    "rf_hyperparameters = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [5, 10, 15]\n",
    "}\n",
    "\n",
    "# Perform grid search for Random Forest model\n",
    "best_rf_model = None\n",
    "best_rf_accuracy = 0\n",
    "for n_estimators in rf_hyperparameters['n_estimators']:\n",
    "    for max_depth in rf_hyperparameters['max_depth']:\n",
    "        model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=42)\n",
    "        model.fit(X_train_vectorized, y_train)\n",
    "        train_accuracy = model.score(X_train_vectorized, y_train)\n",
    "        val_accuracy = model.score(X_val_vectorized, y_val)\n",
    "        if val_accuracy > best_rf_accuracy:\n",
    "            best_rf_model = model\n",
    "            best_rf_accuracy = val_accuracy\n",
    "\n",
    "# Generate classification report for the best Random Forest model\n",
    "y_pred_rf = best_rf_model.predict(X_test_vectorized)\n",
    "print(\"Random Forest Model Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf, target_names=['fake', 'real']))\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "print(\"Validation Accuracy:\", val_accuracy)\n",
    "print(\"Test Accuracy:\", best_rf_model.score(X_test_vectorized, y_test))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98bbc752-1863-45ac-8b2e-6169b97a42b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of fake job postings: 866\n",
      "Number of real job postings: 17014\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "# Determine the number of fake and real job postings\n",
    "num_fake_jobs = job_data[job_data['fraudulent'] == 1].shape[0]\n",
    "num_real_jobs = job_data[job_data['fraudulent'] == 0].shape[0]\n",
    "\n",
    "print(f\"Number of fake job postings: {num_fake_jobs}\")\n",
    "print(f\"Number of real job postings: {num_real_jobs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be70e29-9826-488e-a561-8d27150c5a25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
